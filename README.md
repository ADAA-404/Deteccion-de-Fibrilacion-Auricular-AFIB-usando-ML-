# Deteccion-de-Fibrilacion-Auricular-AFIB-usando-ML ü´Ä

Este proyecto de bioinform√°tica y ciencia de datos presenta un pipeline completo y robusto para la detecci√≥n de la fibrilaci√≥n auricular a partir de grabaciones de Holter. Demuestra la capacidad de procesar grandes vol√∫menes de datos brutos de se√±ales de ECG, extraer caracter√≠sticas biom√©dicas relevantes y entrenar un modelo de machine learning de alta precisi√≥n para identificar esta arritmia com√∫n.  

El objetivo principal es construir un modelo predictivo que pueda diferenciar entre latidos card√≠acos normales y aquellos asociados con la AFIB, un elemento importante para la automatizaci√≥n del diagn√≥stico m√©dico.

## Fuente de Datos üíæ

Este conjunto de datos est√° disponible p√∫blicamente para investigaci√≥n. Los detalles se describen las siguientes citaciones. Importante, incluye esta cita si planeas usar esta base de datos:

> Tsutsui, K., Biton Brimer, S., & Behar, J. (2025). SHDB-AF: a Japanese Holter ECG database of atrial fibrillation (version 1.0.1). PhysioNet. RRID:SCR_007345. https://doi.org/10.13026/n6yq-fq90

> Tsutsui, K., Brimer, S.B., Ben-Moshe, N. et al. SHDB-AF: a Japanese Holter ECG database of atrial fibrillation. Sci Data 12, 454 (2025). https://doi.org/10.1038/s41597-025-04777-4

> Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215‚Äìe220. RRID:SCR_007345.  

## Tecnologias usadas üêç
-   Pandas & NumPy: Para la manipulaci√≥n, limpieza y an√°lisis de datos a gran escala.
-   WFDB: Una librer√≠a especializada para la lectura de se√±ales y anotaciones de bases de datos biom√©dicas, como la base de datos de Holter de la competencia PhysioNet/Computing in Cardiology.
-   Scikit-learn: Para la divisi√≥n de datos, la validaci√≥n del modelo y la evaluaci√≥n de m√©tricas de rendimiento.
-   Imblearn (imbalanced-learn): Para aplicar la t√©cnica de sobremuestreo `SMOTE` en el conjunto de entrenamiento.
-   LightGBM: Una implementaci√≥n de `Gradient Boosting` de alto rendimiento, utilizada para construir el modelo de clasificaci√≥n.
-   Matplotlib & Seaborn: Para la visualizaci√≥n de datos y los resultados del modelo.  

## Consideraciones en Instalaci√≥n ‚öôÔ∏è

Para configurar y ejecutar este proyecto, se recomienda utilizar un entorno `conda`. Estas librerias te ayudar√°n a crear el entorno necesario:

bash
    ```
    pip install pandas numpy wfdb scikit-learn lightgbm seaborn matplotlib imblearn pyarrow
    ```  
    
Configuraci√≥n de Datos**: Aseg√∫rate de que los archivos de datos de la competencia PhysioNet/Computing in Cardiology esten ubicados en la carpeta con la que trabajas dentro de la estructura del proyecto.  
Ejecutar el Script**: Simplemente corre el script principal (o las celdas de tu notebook) para ejecutar el pipeline de procesamiento, modelado y evaluaci√≥n.

## Nota ‚ö†Ô∏è
Para el manejo de este tipo de datos, es necesario entender que entre mas cantidad de datos se tiene, mas procesos para manejarlos se deben implementar sobre todo considerando sus respectivos formatos; para este caso son 8.27 GB de datos, por lo que se debe considerar una estrategia (incluida en el script) para poder procesarlos segun el equipo con el que trabajes. La eficiencia y cuidado para inciar el proyecto es crucial para que puedas hacer las pruebas y aplicaciones necesarias.  

## Ejemplo de Uso üìé

El pipeline de datos procesa con √©xito **+10 millones de latidos** de 80 pacientes, unificando datos de se√±ales de ECG con informaci√≥n cl√≠nica (se debe considerar un balance en la cantidad de datos). Las caracter√≠sticas principales incluyeron:

-   Estad√≠sticas del intervalo RR (`rr_interval`, `rr_std_5_beats`).
-   Estad√≠sticas de la distribuci√≥n (`rr_mean`, `rr_median`, `rr_skew`, `rr_kurtosis`).
-   Datos cl√≠nicos del paciente (`Age_at_Holter`, `Sex`, `HTN`, `CHF`).

Despu√©s de entrenar un modelo `LightGBM` optimizado con una estrategia de muestreo 1:1, los resultados clave en el conjunto de prueba fueron los siguientes:

![LightGBM con el Modelo Optimizado](Images/LightGBM_opt_Model.png)

![Matriz de Confusi√≥n del Modelo Optimizado](Images/confusion_matrix.png)

![Importancia de las Caracter√≠sticas](Images/feature_importance.png)

Considerarmos constrastar la prueba de un entrenamiento con un DataFrame desbalanceado y obtuvimos esta diferencia:

![LightGBM con el Modelo Optimizado con DataFrame desbalanceado](Images/LightGBM_opt_Model_unbalanced.png)

![Matriz de Confusi√≥n del Modelo Optimizado con DataFrame desbalanceado](Images/confusion_matrix_unbalanced.png)

![Importancia de las Caracter√≠sticas con DataFrame desbalanceado](Images/feature_importance_unbalanced.png)

## Contribuciones üñ®Ô∏è

Si te interesa contribuir a este proyecto o usarlo independiente, considera:
-   Hacer un "fork" del repositorio.
-   Crear una nueva rama (`git checkout -b feature/su-caracteristica`).
-   Realizar tus cambios y "commiteelos" (`git commit -am 'Agrega nueva caracter√≠stica'`).
-   Subir los cambios a la rama (`git push origin feature/su-caracteristica`).
-   Abrir un "Pull Request".

## Licencia üìú

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo LICENSE (si aplica) para m√°s detalles.


[English Version](README.en.md)

